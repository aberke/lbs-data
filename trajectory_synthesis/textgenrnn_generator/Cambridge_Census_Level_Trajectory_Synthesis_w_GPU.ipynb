{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cambridge Census Level Trajectory Synthesis w/ GPU",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "# Trajectory synthesis from trained textgenrnn models\n",
        "\n",
        "These trajectories are specific to Cambridge MA.\n",
        "I.e. producing data for users with homes in Camridge MA census tracts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --user textgenrnn\n",
        "\n",
        "from datetime import datetime\n",
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe3yZcBE6HYp",
        "colab_type": "text"
      },
      "source": [
        "Some quick hacking below for use the textgenrnn module internal functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXVZn6iYy0ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In order to use the internal functions, must clone and rename local version \n",
        "# of the module\n",
        "!git clone https://github.com/minimaxir/textgenrnn.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60fh1KFCzeO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDN7cQfPzsgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv textgenrnn clonedtextgenrnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKQgFaDG0AM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from clonedtextgenrnn.textgenrnn import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrz3SO40Wti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verify this function can be used:\n",
        "utils.synthesize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foU5V7M06Ocj",
        "colab_type": "text"
      },
      "source": [
        "-- module import/hacking done --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import textgenrnn\n",
        "\n",
        "def get_model_generator(model_name):\n",
        "  return textgenrnn.textgenrnn(weights_path='./{}_weights.hdf5'.format(model_name),\n",
        "                      vocab_path='./{}_vocab.json'.format(model_name),\n",
        "                      config_path='./{}_config.json'.format(model_name),\n",
        "                      name=model_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_temperatures = [0.8, 0.9, 1.0]\n",
        "def get_output_filename(model_name, temperature):\n",
        "    return 'generated-cambridge-{}-temperature:{}.txt'.format(model_name, temperature)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DuKFWv1mUNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Read in the mapping of (home, work) label pairs -> count\n",
        "def get_prefixes_to_counts_dict(fname):\n",
        "    prefixes_to_counts_dict = None\n",
        "    with open(fname) as json_file:\n",
        "        prefixes_to_counts_dict = json.load(json_file)\n",
        "    return prefixes_to_counts_dict\n",
        "\n",
        "  \n",
        "seq_length = 122\n",
        "\n",
        "def filter_to_seq_length(sequences):\n",
        "    return [seq for seq in sequences if (len(seq.split()) == seq_length)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjDv9fYvvDmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generate_sequences(generator, temperature, prefix, make_num):\n",
        "    # Current problem: not always getting desired sequence length (TODO: fork and hack on textgenrnn code to fix this)\n",
        "    # Solution for now: loop to hack around this\n",
        "    ss = []\n",
        "    while len(ss) < make_num:\n",
        "        n = (make_num - len(ss))*2\n",
        "        generated_sequences = utils.synthesize(\n",
        "            [generator], n=n, prefix=prefix, temperature=[temperature],\n",
        "            return_as_list=True, max_gen_length=seq_length+1, stop_tokens=['hack'])\n",
        "        ss += filter_to_seq_length(generated_sequences)\n",
        "    return ss[:make_num]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkbkSQGd7mqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "# Generate the sequences!\n",
        "# Generate 2 synthetic sequences for every real sequence\n",
        "count_multiplier = 2\n",
        "\n",
        "# NOTE: Generation is done for data Cambridge specific data.\n",
        "# Only using prefixes where the home label is a Cambridge GEOID\n",
        "input_trajectories_prefixes_to_counts_filename = './relabeled_cambridge_trajectories_1_workweek_prefixes_to_counts.json'\n",
        "prefixes_to_counts_dict = get_prefixes_to_counts_dict(input_trajectories_prefixes_to_counts_filename)\n",
        "\n",
        "# For debugging...\n",
        "sequences = None\n",
        "\n",
        "# generate with a variety of temperatures, for given model\n",
        "def generate_for_model(model_name):\n",
        "  generator = get_model_generator(model_name)\n",
        "  print('\\nwill generate trajectories for temperatures %s and output to files %s\\n' % (generate_temperatures, [get_output_filename(model_name, t) for t in generate_temperatures]))\n",
        "  for temperature in generate_temperatures:\n",
        "      output_fname = get_output_filename(model_name, temperature)\n",
        "      print('%s : generating trajectories and saving to file: %s' % (datetime.now(), output_fname))\n",
        "      sequences = []\n",
        "      i = 0\n",
        "      for prefix_labels, count in prefixes_to_counts_dict.items():\n",
        "          if i % 100 == 0:\n",
        "              print('%s : %s : generated %s sequences...' % (datetime.now(), i, len(sequences)))\n",
        "          i += 1\n",
        "          \n",
        "          # Add an extra space so that the work prefix label has proper end and model continues to next label\n",
        "          prefix = '%s ' % prefix_labels\n",
        "          make_num = count*count_multiplier\n",
        "          sequences += generate_sequences(generator, temperature, prefix, make_num=make_num)\n",
        "      print('writing sequences to file', output_fname)\n",
        "      with open(output_fname, 'w') as f:\n",
        "          for seq in sequences:\n",
        "              f.write('{}\\n'.format(seq))\n",
        "      print('wrote to file')\n",
        "      # Make sure the file is finished being written - annoying colab issue\n",
        "      time.sleep(120)\n",
        "      files.download(output_fname)\n",
        "      print('downloaded file')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzD0I_-OBQT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'trajectories-rnn_bidirectional:False-max_len:24-rnn_layers:2-rnn_size:128-dropout:0.2-dim_embeddings:50'\n",
        "generate_for_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAi7jEIqHaYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('generated-cambridge-trajectories-rnn_bidirectional:False-max_len:24-rnn_layers:2-rnn_size:128-dropout:0.2-dim_embeddings:50-temperature:1.0.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wby4amADhsu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmRhbD-JAAsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'trajectories-rnn_bidirectional:False-max_len:24-rnn_layers:2-rnn_size:128-dropout:0.1-dim_embeddings:100'\n",
        "generate_for_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQu3PUlLAAoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'trajectories-rnn_bidirectional:False-max_len:24-rnn_layers:2-rnn_size:128-dropout:0.1-dim_embeddings:50'\n",
        "generate_for_model(model_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}