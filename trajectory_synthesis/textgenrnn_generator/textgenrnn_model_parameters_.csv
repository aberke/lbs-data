,default,default,default,A,A,A,B,B,B,C,C,C,D,D,D,E,E,E,O,O,O,default-bidirectional,default-bidirectional,default-bidirectional,A-bidirectional,A-bidirectional,A-bidirectional,B-bidirectional,B-bidirectional,B-bidirectional,C-bidirectional,C-bidirectional,C-bidirectional,D-bidirectional,D-bidirectional,D-bidirectional,E-bidirectional,E-bidirectional,E-bidirectional,O-bidirectional,O-bidirectional,O-bidirectional,N,N,N,original,original,original,P,P,P,P-bidirectional,P-bidirectional,P-bidirectional,Q-bidirectional,Q-bidirectional,Q-bidirectional,R-bidirectional,R-bidirectional,R-bidirectional,S-bidirectional,S-bidirectional,S-bidirectional,T-bidirectional,T-bidirectional,T-bidirectional,U-bidirectional,U-bidirectional,U-bidirectional
rnn_bidirectional,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE,TRUE
max_length,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,48,48,48,48,48,48,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,48,48,48,48,48,48,50,50,50,50,50,50,50,50,50,50,50,50,60,60,60,50,50,50,50,50,50,50,50,50,50,50,50
rnn_layers,2,2,2,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,2,2,2,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2
rnn_size,128,128,128,128,128,128,256,256,256,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,256,256,256,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,256,256,256,256,256,256
dropout,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.2,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.2,0.2,0.2,0.2,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.2,0.2,0.2,0.2,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.3,0.3,0.3,0.4,0.4,0.4
dim_embeddings,50,50,50,50,50,50,50,50,50,50,50,50,100,100,100,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,100,100,100,50,50,50,50,50,50,128,128,128,128,128,128,128,128,128,128,128,128,128,128,128,64,64,64,128,128,128,100,100,100,100,100,100
temperature,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.8,0.8,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1,0.8,0.9,1
batch size,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024,1024
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,modifies original by not being bidirectional,,,,,,training  in progress on matlaber4,,PID 14858,modifies original with dropout,,,modifies original with increased max_length,,,modifies original with smaller embedding,,,modifies original with RNN layers,,,training on matlaber7,PID,15437,training on matlaber7,PID,15637
,,,,,,,,,,,,,,,,model trained...,model trained...,model trained...,model trained...,model trained...,model trained...,,,,,,,,,,,,,,,,,,,training on matlaber1,nohup python3 model_trainer.py > process_O_bi.out 2> process_O_bi.err < /dev/null &,PID: 3466,in progress on matlaber11,PID: 1216,,name:,synthetic_trajectories_,,,,,training in progress...,on matlaber4,PID 14668,training  on matlaber11,PID,1812,training on matlaber1,PID,23435,training  on matlaber4,PID,15884,,,,,,
generated for cambridge,GPU,yes,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,no,no,no,no,no,no,remote,done - need to copy over,done - need to copy over,yes,yes,yes,,,,,,,,,,,,,TODO,TODO,TODO,,,,,,,,,,,,,,,,,,,,,,,,,,,
generated for general sample,GPU,yes,yes,TODO,TODO,,yes,yes,yes,done,done,done,TODO,TODO,TODO,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,,,,,,,,,,,,,,,,,,,done,done,done,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,UH OH! something weird happend here.  loss goes to nan...,,,,,,,,,,,,looks like loss plateaus around epoch  12ish,,,loss after 26 epochs: 0.59ish,,,,,,generating  prematurely after 15 epochs where loss ~0.65,on matlaber11,PID: 5409,,,,,,,,,
,,,,,,,,,,, ,output looked normal for loss,,,,,,,training wierdness: UH OH!,,,,,,loss looks normal,,,,,,,,,,,,again!,,,epoch 16: loss 0.61ish,,,,,,,,,generating at epoch 16,on matlaber11,PID: 4802,generating after 26 epochs on matlaber4,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,finished after 72 epochs,,,,,,,loss at 18/75 epochs: 0.714,,,,,,finished after 67 epochs,,,,,,,,,,,,new training,at  epoch 20ish loss goes to nan  again!,,doing  generation after  training on 17 epochs,on matlaber4,PID: 16478,,,,,,,,,,PID,25068,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,then goes up!,,,,,,,,,,,,,,,,,,,,,nohup python3 generator_O_bi.py > process_O_bi_after_17_epochs.out 2> process_O_after_17_epochs.err < /dev/null &,,,,,,,,,but it didn't plateau! loss continued to decreate,TODO: generate again,,,,,,,,,,,,,,,,,,,